{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from soln.dataset import AllCategoricalsFeaturizer\n",
    "from soln.dataset import generate_xv_splits\n",
    "from soln.dataset import get_augmented_train_and_test_set\n",
    "from soln.utils import eval_model\n",
    "from soln.utils import train_model\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 100 ms, total: 13.6 s\n",
      "Wall time: 14.2 s\n",
      "CPU times: user 128 ms, sys: 20 ms, total: 148 ms\n",
      "Wall time: 152 ms\n",
      "(27270, 53) (27270,) (2943, 53) (2943,)\n"
     ]
    }
   ],
   "source": [
    "%time aug_train_set, aug_test_set = get_augmented_train_and_test_set()\n",
    "%time X_train, y_train, X_test, y_test = next(generate_xv_splits(aug_train_set))\n",
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 1: Everything.\n",
    "\n",
    "layer1_params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    'num_rounds': 1000,\n",
    "    'gamma': 0.0,\n",
    "    'eta': 0.02,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.6,\n",
    "}\n",
    "\n",
    "def layer1_get_indices(X):\n",
    "    return np.ones(len(X), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 992 ms, total: 2min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "layer1_featurizer = AllCategoricalsFeaturizer()\n",
    "%time layer1 = train_model(layer1_params, layer1_get_indices, layer1_featurizer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on everything, test on everything:\n",
      "(27270, 53)\n",
      "(27270, 53)\n",
      "(2943, 53)\n",
      "train RMSLE 0.124960740984\n",
      "test RMSLE 0.227403087285\n"
     ]
    }
   ],
   "source": [
    "layer1_train_results = eval_model(layer1['model'], layer1_get_indices, layer1_featurizer, X_train, y_train)\n",
    "layer1_test_results = eval_model(layer1['model'], layer1_get_indices, layer1_featurizer, X_test, y_test)\n",
    "print \"Train on everything, test on everything:\"\n",
    "print layer1['X_train'].shape\n",
    "print layer1_train_results['X_eval'].shape\n",
    "print layer1_test_results['X_eval'].shape\n",
    "print \"train RMSLE\", layer1_train_results['rmsle']\n",
    "print \"test RMSLE\", layer1_test_results['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 2: Uncommon brackets.\n",
    "\n",
    "layer2_params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    'num_rounds': 1000,\n",
    "    'gamma': 0.0,\n",
    "    'eta': 0.02,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.6,\n",
    "}\n",
    "\n",
    "common_brackets = [\n",
    "    (1, 2, 5, 10, 25, 50, 100, 250),\n",
    "    (1, 6, 20),\n",
    "    (1, 2, 3, 5, 10, 20),\n",
    "    (1, 2, 5, 10, 25, 50, 100),\n",
    "    (5, 19, 20),\n",
    "]\n",
    "\n",
    "def layer2_get_indices(X):\n",
    "    return ~X.bracketing_pattern.isin(common_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.6 s, sys: 324 ms, total: 59.9 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "layer2_featurizer = AllCategoricalsFeaturizer()\n",
    "%time layer2 = train_model(layer2_params, layer2_get_indices, layer2_featurizer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on everything, test on uncommon bracket:\n",
      "(987, 53)\n",
      "test RMSLE 0.369369099906\n"
     ]
    }
   ],
   "source": [
    "print \"Train on everything, test on uncommon brackets:\"\n",
    "tmp = eval_model(layer1['model'], layer2_get_indices, layer1_featurizer, X_test, y_test)\n",
    "print tmp['X_eval'].shape\n",
    "print \"test RMSLE\", tmp['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on uncommon bracket, test on uncommon bracket:\n",
      "(8221, 53)\n",
      "(8221, 53)\n",
      "(987, 53)\n",
      "train RMSLE 0.163275589812\n",
      "test RMSLE 0.345135857409\n"
     ]
    }
   ],
   "source": [
    "layer2_train_results = eval_model(layer2['model'], layer2_get_indices, layer2_featurizer, X_train, y_train)\n",
    "layer2_test_results = eval_model(layer2['model'], layer2_get_indices, layer2_featurizer, X_test, y_test)\n",
    "print \"Train on uncommon brackets, test on uncommon brackets:\"\n",
    "print layer2['X_train'].shape\n",
    "print layer2_train_results['X_eval'].shape\n",
    "print layer2_test_results['X_eval'].shape\n",
    "print \"train RMSLE\", layer2_train_results['rmsle']\n",
    "print \"test RMSLE\", layer2_test_results['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 and layer 2 together:\n",
      "(2943,)\n",
      "test RMSLE 0.214255159159\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = pd.Series(layer1_test_results['y_eval_pred'], copy=True)\n",
    "y_test_pred[layer2_test_results['eval_is']] = layer2_test_results['y_eval_pred']\n",
    "rmsle = np.sqrt(mean_squared_error(y_test.values, y_test_pred.values))\n",
    "print \"Layer 1 and layer 2 together:\"\n",
    "print y_test_pred.shape\n",
    "print \"test RMSLE\", rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer 3: Empty bracket.\n",
    "\n",
    "layer3_params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    'num_rounds': 1000,\n",
    "    'gamma': 0.0,\n",
    "    'eta': 0.02,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.6,\n",
    "}\n",
    "\n",
    "def layer3_get_indices(X):\n",
    "    return (X.bracketing_pattern == ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35 s, sys: 208 ms, total: 35.2 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "layer3_featurizer = AllCategoricalsFeaturizer()\n",
    "%time layer3 = train_model(layer3_params, layer3_get_indices, layer3_featurizer, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on everything, test on empty bracket:\n",
      "(493, 53)\n",
      "test RMSLE 0.402430706857\n"
     ]
    }
   ],
   "source": [
    "print \"Train on everything, test on empty bracket:\"\n",
    "tmp = eval_model(layer1['model'], layer3_get_indices, layer1_featurizer, X_test, y_test)\n",
    "print tmp['X_eval'].shape\n",
    "print \"test RMSLE\", tmp['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on uncommon brackets, test on empty bracket:\n",
      "(493, 53)\n",
      "test RMSLE 0.378887498903\n"
     ]
    }
   ],
   "source": [
    "print \"Train on uncommon brackets, test on empty bracket:\"\n",
    "tmp = eval_model(layer2['model'], layer3_get_indices, layer2_featurizer, X_test, y_test)\n",
    "print tmp['X_eval'].shape\n",
    "print \"test RMSLE\", tmp['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on empty bracket, test on empty bracket:\n",
      "(4249, 53)\n",
      "(4249, 53)\n",
      "(493, 53)\n",
      "train RMSLE 0.146880176789\n",
      "test RMSLE 0.377893012301\n"
     ]
    }
   ],
   "source": [
    "layer3_train_results = eval_model(layer3['model'], layer3_get_indices, layer3_featurizer, X_train, y_train)\n",
    "layer3_test_results = eval_model(layer3['model'], layer3_get_indices, layer3_featurizer, X_test, y_test)\n",
    "print \"Train on empty bracket, test on empty bracket:\"\n",
    "print layer3['X_train'].shape\n",
    "print layer3_train_results['X_eval'].shape\n",
    "print layer3_test_results['X_eval'].shape\n",
    "print \"train RMSLE\", layer3_train_results['rmsle']\n",
    "print \"test RMSLE\", layer3_test_results['rmsle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 and layer 2 and layer 3 together:\n",
      "(2943,)\n",
      "test RMSLE 0.213960742254\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = pd.Series(layer1_test_results['y_eval_pred'], copy=True)\n",
    "y_test_pred[layer2_test_results['eval_is']] = layer2_test_results['y_eval_pred']\n",
    "y_test_pred[layer3_test_results['eval_is']] = layer3_test_results['y_eval_pred']\n",
    "rmsle = np.sqrt(mean_squared_error(y_test.values, y_test_pred.values))\n",
    "print \"Layer 1 and layer 2 and layer 3 together:\"\n",
    "print y_test_pred.shape\n",
    "print \"test RMSLE\", rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
